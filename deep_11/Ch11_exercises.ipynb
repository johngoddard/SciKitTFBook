{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden, name='hidden1', activation=tf.nn.elu, \n",
    "                          kernel_initializer=he_init)\n",
    "hidden2 = tf.layers.dense(hidden1, n_hidden, name='hidden2', activation=tf.nn.elu, \n",
    "                          kernel_initializer=he_init)\n",
    "hidden3 = tf.layers.dense(hidden2, n_hidden, name='hidden3', \n",
    "                          activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "hidden4 = tf.layers.dense(hidden3, n_hidden, name='hidden4', \n",
    "                          activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "hidden5 = tf.layers.dense(hidden4, n_hidden, name='hidden5', \n",
    "                          activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "\n",
    "logits = tf.layers.dense(hidden4, n_outputs, name='outputs', kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "learning_rate = 0.001\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train1 = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_valid1 = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid1 = mnist.validation.labels[mnist.validation.labels < 5]\n",
    "X_test1 = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test1 = mnist.test.labels[mnist.test.labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs=1000, batch_size = 20, max_checks_without_progress=20):\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = 'tf_logs'\n",
    "    logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "    loss_summary = tf.summary.scalar('loss', loss)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "    checks_without_progress = 0\n",
    "    best_loss = np.infty\n",
    "    step_counter = 0\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            rnd_idx = np.random.permutation(len(X_train1))\n",
    "            for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "                X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "                sess.run([training_op, extra_update_ops], \n",
    "                         feed_dict={ X: X_batch, y: y_batch, training: True })\n",
    "                if step_counter % 10 == 0:\n",
    "                    summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                    step = step_counter\n",
    "                    file_writer.add_summary(summary_str, step)\n",
    "                step_counter += 1\n",
    "            loss_val, acc_val = sess.run([loss, accuracy], feed_dict={ X: X_valid1, y: y_valid1 })\n",
    "            if loss_val < best_loss:\n",
    "                checks_without_progress = 0\n",
    "                best_loss = loss_val\n",
    "                save_path = saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            else:\n",
    "                checks_without_progress += 1\n",
    "                if checks_without_progress > max_checks_without_progress:\n",
    "                    file_writer.close()\n",
    "                    print('Early stop!')\n",
    "                    break\n",
    "            print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "        print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "\n",
    "def dnn_bn(inputs, n_hidden_layers=5, n_neurons=100, name=None,\n",
    "        activation=tf.nn.elu, initializer=he_init, with_dropout=False, dropout_rate=0.5):\n",
    "    with tf.variable_scope(name, 'dnn_bn'):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            raw_output = tf.layers.dense(inputs, n_neurons, kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            bn_inputs = my_batch_norm_layer(raw_output)\n",
    "            inputs = activation(bn_inputs)\n",
    "            if with_dropout:\n",
    "                inputs = tf.layers.dropout(inputs, dropout_rate, training=training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_bn_outputs = dnn_bn(X, with_dropout=True)\n",
    "\n",
    "logits = tf.layers.dense(dnn_bn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "learning_rate = 0.001\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.120866\tBest loss: 0.120866\tAccuracy: 96.09%\n",
      "1\tValidation loss: 0.100900\tBest loss: 0.100900\tAccuracy: 96.52%\n",
      "2\tValidation loss: 0.094376\tBest loss: 0.094376\tAccuracy: 97.26%\n",
      "3\tValidation loss: 0.090971\tBest loss: 0.090971\tAccuracy: 97.15%\n",
      "4\tValidation loss: 0.075347\tBest loss: 0.075347\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.073190\tBest loss: 0.073190\tAccuracy: 97.69%\n",
      "6\tValidation loss: 0.070634\tBest loss: 0.070634\tAccuracy: 97.54%\n",
      "7\tValidation loss: 0.064752\tBest loss: 0.064752\tAccuracy: 97.73%\n",
      "8\tValidation loss: 0.060272\tBest loss: 0.060272\tAccuracy: 97.85%\n",
      "9\tValidation loss: 0.059940\tBest loss: 0.059940\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.054780\tBest loss: 0.054780\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.050559\tBest loss: 0.050559\tAccuracy: 98.36%\n",
      "12\tValidation loss: 0.053041\tBest loss: 0.050559\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.048494\tBest loss: 0.048494\tAccuracy: 98.48%\n",
      "14\tValidation loss: 0.048790\tBest loss: 0.048494\tAccuracy: 98.32%\n",
      "15\tValidation loss: 0.049896\tBest loss: 0.048494\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.049836\tBest loss: 0.048494\tAccuracy: 98.44%\n",
      "17\tValidation loss: 0.046070\tBest loss: 0.046070\tAccuracy: 98.59%\n",
      "18\tValidation loss: 0.053217\tBest loss: 0.046070\tAccuracy: 98.44%\n",
      "19\tValidation loss: 0.040644\tBest loss: 0.040644\tAccuracy: 98.67%\n",
      "20\tValidation loss: 0.040146\tBest loss: 0.040146\tAccuracy: 98.71%\n",
      "21\tValidation loss: 0.044359\tBest loss: 0.040146\tAccuracy: 98.67%\n",
      "22\tValidation loss: 0.039501\tBest loss: 0.039501\tAccuracy: 98.98%\n",
      "23\tValidation loss: 0.040014\tBest loss: 0.039501\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.043075\tBest loss: 0.039501\tAccuracy: 98.63%\n",
      "25\tValidation loss: 0.042255\tBest loss: 0.039501\tAccuracy: 98.59%\n",
      "26\tValidation loss: 0.039372\tBest loss: 0.039372\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.039658\tBest loss: 0.039372\tAccuracy: 98.79%\n",
      "28\tValidation loss: 0.037407\tBest loss: 0.037407\tAccuracy: 98.75%\n",
      "29\tValidation loss: 0.035250\tBest loss: 0.035250\tAccuracy: 98.98%\n",
      "30\tValidation loss: 0.038645\tBest loss: 0.035250\tAccuracy: 98.91%\n",
      "31\tValidation loss: 0.037540\tBest loss: 0.035250\tAccuracy: 98.83%\n",
      "32\tValidation loss: 0.037746\tBest loss: 0.035250\tAccuracy: 98.83%\n",
      "33\tValidation loss: 0.036833\tBest loss: 0.035250\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.041295\tBest loss: 0.035250\tAccuracy: 98.44%\n",
      "35\tValidation loss: 0.034807\tBest loss: 0.034807\tAccuracy: 98.91%\n",
      "36\tValidation loss: 0.035959\tBest loss: 0.034807\tAccuracy: 98.87%\n",
      "37\tValidation loss: 0.041334\tBest loss: 0.034807\tAccuracy: 98.75%\n",
      "38\tValidation loss: 0.036869\tBest loss: 0.034807\tAccuracy: 98.79%\n",
      "39\tValidation loss: 0.035819\tBest loss: 0.034807\tAccuracy: 98.79%\n",
      "40\tValidation loss: 0.035295\tBest loss: 0.034807\tAccuracy: 98.83%\n",
      "41\tValidation loss: 0.038116\tBest loss: 0.034807\tAccuracy: 98.83%\n",
      "42\tValidation loss: 0.035844\tBest loss: 0.034807\tAccuracy: 98.87%\n",
      "43\tValidation loss: 0.033016\tBest loss: 0.033016\tAccuracy: 98.83%\n",
      "44\tValidation loss: 0.037185\tBest loss: 0.033016\tAccuracy: 98.87%\n",
      "45\tValidation loss: 0.038345\tBest loss: 0.033016\tAccuracy: 98.79%\n",
      "46\tValidation loss: 0.033332\tBest loss: 0.033016\tAccuracy: 98.94%\n",
      "47\tValidation loss: 0.034198\tBest loss: 0.033016\tAccuracy: 99.02%\n",
      "48\tValidation loss: 0.034333\tBest loss: 0.033016\tAccuracy: 98.98%\n",
      "49\tValidation loss: 0.031349\tBest loss: 0.031349\tAccuracy: 99.02%\n",
      "50\tValidation loss: 0.032170\tBest loss: 0.031349\tAccuracy: 98.91%\n",
      "51\tValidation loss: 0.035739\tBest loss: 0.031349\tAccuracy: 98.91%\n",
      "52\tValidation loss: 0.032166\tBest loss: 0.031349\tAccuracy: 98.94%\n",
      "53\tValidation loss: 0.030609\tBest loss: 0.030609\tAccuracy: 98.98%\n",
      "54\tValidation loss: 0.030903\tBest loss: 0.030609\tAccuracy: 98.94%\n",
      "55\tValidation loss: 0.030970\tBest loss: 0.030609\tAccuracy: 98.91%\n",
      "56\tValidation loss: 0.034823\tBest loss: 0.030609\tAccuracy: 98.87%\n",
      "57\tValidation loss: 0.030717\tBest loss: 0.030609\tAccuracy: 99.10%\n",
      "58\tValidation loss: 0.035377\tBest loss: 0.030609\tAccuracy: 98.83%\n",
      "59\tValidation loss: 0.033283\tBest loss: 0.030609\tAccuracy: 98.83%\n",
      "60\tValidation loss: 0.035557\tBest loss: 0.030609\tAccuracy: 98.83%\n",
      "61\tValidation loss: 0.031090\tBest loss: 0.030609\tAccuracy: 99.10%\n",
      "62\tValidation loss: 0.030121\tBest loss: 0.030121\tAccuracy: 98.98%\n",
      "63\tValidation loss: 0.032710\tBest loss: 0.030121\tAccuracy: 98.94%\n",
      "64\tValidation loss: 0.033070\tBest loss: 0.030121\tAccuracy: 98.94%\n",
      "65\tValidation loss: 0.034283\tBest loss: 0.030121\tAccuracy: 98.83%\n",
      "66\tValidation loss: 0.032318\tBest loss: 0.030121\tAccuracy: 98.91%\n",
      "67\tValidation loss: 0.035212\tBest loss: 0.030121\tAccuracy: 98.91%\n",
      "68\tValidation loss: 0.033111\tBest loss: 0.030121\tAccuracy: 98.94%\n",
      "69\tValidation loss: 0.031034\tBest loss: 0.030121\tAccuracy: 98.79%\n",
      "70\tValidation loss: 0.029725\tBest loss: 0.029725\tAccuracy: 98.94%\n",
      "71\tValidation loss: 0.030592\tBest loss: 0.029725\tAccuracy: 98.94%\n",
      "72\tValidation loss: 0.030950\tBest loss: 0.029725\tAccuracy: 98.94%\n",
      "73\tValidation loss: 0.031499\tBest loss: 0.029725\tAccuracy: 98.98%\n",
      "74\tValidation loss: 0.034235\tBest loss: 0.029725\tAccuracy: 98.98%\n",
      "75\tValidation loss: 0.033938\tBest loss: 0.029725\tAccuracy: 99.02%\n",
      "76\tValidation loss: 0.031118\tBest loss: 0.029725\tAccuracy: 98.91%\n",
      "77\tValidation loss: 0.032526\tBest loss: 0.029725\tAccuracy: 98.91%\n",
      "78\tValidation loss: 0.029329\tBest loss: 0.029329\tAccuracy: 99.22%\n",
      "79\tValidation loss: 0.032540\tBest loss: 0.029329\tAccuracy: 99.02%\n",
      "80\tValidation loss: 0.033373\tBest loss: 0.029329\tAccuracy: 98.79%\n",
      "81\tValidation loss: 0.030464\tBest loss: 0.029329\tAccuracy: 98.98%\n",
      "82\tValidation loss: 0.031826\tBest loss: 0.029329\tAccuracy: 99.06%\n",
      "83\tValidation loss: 0.028786\tBest loss: 0.028786\tAccuracy: 98.98%\n",
      "84\tValidation loss: 0.031227\tBest loss: 0.028786\tAccuracy: 98.98%\n",
      "85\tValidation loss: 0.030224\tBest loss: 0.028786\tAccuracy: 99.06%\n",
      "86\tValidation loss: 0.030521\tBest loss: 0.028786\tAccuracy: 98.98%\n",
      "87\tValidation loss: 0.025697\tBest loss: 0.025697\tAccuracy: 99.22%\n",
      "88\tValidation loss: 0.031406\tBest loss: 0.025697\tAccuracy: 98.91%\n",
      "89\tValidation loss: 0.028698\tBest loss: 0.025697\tAccuracy: 99.10%\n",
      "90\tValidation loss: 0.029639\tBest loss: 0.025697\tAccuracy: 98.94%\n",
      "91\tValidation loss: 0.031383\tBest loss: 0.025697\tAccuracy: 98.87%\n",
      "92\tValidation loss: 0.036789\tBest loss: 0.025697\tAccuracy: 98.83%\n",
      "93\tValidation loss: 0.031966\tBest loss: 0.025697\tAccuracy: 99.06%\n",
      "94\tValidation loss: 0.034605\tBest loss: 0.025697\tAccuracy: 98.83%\n",
      "95\tValidation loss: 0.029473\tBest loss: 0.025697\tAccuracy: 98.98%\n",
      "96\tValidation loss: 0.031011\tBest loss: 0.025697\tAccuracy: 99.02%\n",
      "97\tValidation loss: 0.030644\tBest loss: 0.025697\tAccuracy: 98.98%\n",
      "98\tValidation loss: 0.028784\tBest loss: 0.025697\tAccuracy: 98.91%\n",
      "99\tValidation loss: 0.030565\tBest loss: 0.025697\tAccuracy: 98.98%\n",
      "100\tValidation loss: 0.031061\tBest loss: 0.025697\tAccuracy: 98.94%\n",
      "101\tValidation loss: 0.028513\tBest loss: 0.025697\tAccuracy: 98.98%\n",
      "102\tValidation loss: 0.027890\tBest loss: 0.025697\tAccuracy: 99.02%\n",
      "103\tValidation loss: 0.029165\tBest loss: 0.025697\tAccuracy: 98.94%\n",
      "104\tValidation loss: 0.027326\tBest loss: 0.025697\tAccuracy: 98.94%\n",
      "105\tValidation loss: 0.027744\tBest loss: 0.025697\tAccuracy: 98.94%\n",
      "106\tValidation loss: 0.028451\tBest loss: 0.025697\tAccuracy: 98.91%\n",
      "107\tValidation loss: 0.028082\tBest loss: 0.025697\tAccuracy: 99.02%\n",
      "Early stop!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 99.34%\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
